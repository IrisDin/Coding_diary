---
cover: >-
  https://images.squarespace-cdn.com/content/v1/5daddb33ee92bf44231c2fef/1593634997762-75P05A5AKO859N5G9OMU/medical-algorithms.gif
coverY: 0
---

# 🔢 Stat

一个随机事件的概率是一个介于0与1之间的实数，这个实数的大小反映了这个事件发生的可能性。因此，概率为0意味着这个事件不可能发生（不可能事件），概率为1意味着这个事件必然发生（必然事件）。

期待值

![](<../.gitbook/assets/截屏2022-04-19 下午11.57.44.png>)

概率论

随机变量



**Central limit therom(中心极限定理)**

> 中心极限定理指的是给定一个任意分布的总体。我每次从这些总体中随机抽取 n 个抽样，一共抽 m 次。 然后把这 m 组抽样分别求出平均值。 这些平均值的分布接近正态分布。

我们先举个**栗子?**

_现在我们要统计全国的人的体重，看看我国平均体重是多少。当然，我们把全国所有人的体重都调查一遍是不现实的。所以我们打算一共调查1000组，每组50个人。 然后，我们求出第一组的体重平均值、第二组的体重平均值，一直到最后一组的体重平均值。中心极限定理说：这些平均值是呈现正态分布的。并且，随着组数的增加，效果会越好。 最后，当我们再把1000组算出来的平均值加起来取个平均值，这个平均值会接近全国平均体重。_

其中要注意的几点：

1. **总体本身的分布不要求正态分布**\
   上面的例子中，人的体重是正态分布的。但如果我们的例子是掷一个骰子（平均分布），最后每组的平均值也会组成一个正态分布。
2. **样本每组要足够大，但也不需要太大**\
   取样本的时候，一般认为，每组大于等于30个，即可让中心极限定理发挥作用。

也就是说

![](<../.gitbook/assets/截屏2022-04-25 下午2.53.06.png>)

随着n（样本容量增加）sample mean会越来越接近expected value

sample variance等于 theoretical variance的 1/n

举例：

当S=1的时候  variance = 1

当S=10的时候 variance = 1/10

### 统计推论(statistical inference)**：**

根据样本资料 (sample)，估计、预测、决定总体 (population)的特性。

因为样本资料的信息小于总体的信息，这样的推论无法完全准确。

推论的可靠度量度包含信心水平 **(confidence level)**、显著性差异 **(signifance level)**。

统计推论有2种作法:

**(1)估计(estimation)**

**(2)假设检定(hypothesis testing)**

****

A **95%** **confidence interval** \[a,b] means: (let's assume the true value p)

There is a probability of **95%** that this estimate, a\<p\<b, will 100% succeed.

There is a probability of **5%** that this estimate, a\<p\<b, will 100% fail.



有时候想获得总体的某个精确数值，如某地区平均收入，但采集全体数据太难，因此希望抽取一个样本，用样本数据代表总体数据。

直接用样本数据代替总体数据称为点估计，如抽取1000人，认为他们的平均收入2000元就是该地平均收入。

但是每次抽样对象不同，会使抽样结果产生误差，因此只能获得一个总体数据的估计值，而不是精确值，因此点估计主要为许多定性研究提供一定的参考数据，或在对总体数据要求不精确时使用。

这时我们希望获得一个总体数据的合理取值范围，比如当地平均收入在1500\~2500元之间，这种估计方式叫区间估计，这个范围就叫置信区间。这个区间通过在样本数据（点估计值）上加减一个边际误差获得。

在做区间估计的时候，我们还要设置一个可能性，预测总体数据精确值落在这个范围内的可能性是多少，这个可能性就叫置信水平，我们希望保证在这个可能性上精确值确实在这个范围内。要求落在这个范围的可能性越高，则需要通过加大边际误差使范围更大，大到一定程度则会产生一些正确但无用的结论，如我们有100%的把握，满分100分的考试，全校平均分在0\~100之间，这个结论完全正确但没什么用。

常用的平均值指标有2个：

平均值，如抽样鸡腿的平均重量为150克。

比例，如抽样鸡腿的卫生合格率为99.9%

名词总结

**置信区间**：总体参数所在范围，是区间估计的计算目标，数值是点估计值±边际误差

**置信水平（置信度）**：表示总体参数落在置信区间的可能性，用百分数表示，常用95%。

**置信系数**：小数形式的置信水平，如0.95。

**显著性水平**：表示总体参数不落在置信区间的可能性，用α表示，（1-α）100%即为置信水平



**descriptive statistics vs  statistical  inference**

描述统计（**descriptive statistics**）就是把数据信息通过图，频数表，平均值，方差，中位数等原样表达出来，它并不会做出任何结论。

如果你做结论了，比如，今年比去年客户量显著增加了，就不是描述统计，而是推断统计。

条形图上你可以看出今年客户量是1000人，去年是800人。条形图并没有说今年客户量比去年客户量不是随机因素导致的增加，它只是把数据原样展示了出来。要做出今年比去年客户量增加不是随机因素导致的，而是显著的增加，你就要使用假设检验做检验，假设检验属于推断统计。

****



### **零假设/一类错误和二类错误**

<img src="../.gitbook/assets/file.drawing (3).svg" alt="" class="gitbook-drawing">



### Linear Regression:

**什么是回归？**

**回归算法**是相对**分类算法**而言的，与我们想要预测的目标变量y的值类型有关。如果**目标变量y是分类型变量**，如预测用户的性别（男、女），预测月季花的颜色（红、白、黄……），预测是否患有肺癌（是、否），那我们就需要用分类算法去拟合训练数据并做出预测；

如果**y是连续型变量**，如预测用户的收入（4千，2万，10万……），预测员工的通勤距离（500m，1km，2万里……），预测患肺癌的概率（1%，50%，99%……），我们则需要用回归模型。



有时**分类问题也可以转化为回归问题**，例如刚刚举例的肺癌预测，我们可以用回归模型先预测出患肺癌的概率，然后再**给定一个阈值**，例如50%，概率值在50%以下的人划为没有肺癌，50%以上则认为患有肺癌



![](<../.gitbook/assets/截屏2022-05-02 下午7.44.20.png>)

![](<../.gitbook/assets/截屏2022-05-02 下午7.44.55.png>)

![](<../.gitbook/assets/截屏2022-05-02 下午7.45.06 (1).png>)

![](<../.gitbook/assets/截屏2022-05-02 下午7.45.32.png>)

![](<../.gitbook/assets/截屏2022-05-02 下午7.45.53.png>)

![](<../.gitbook/assets/截屏2022-05-02 下午7.52.42.png>)

![](<../.gitbook/assets/截屏2022-05-02 下午7.52.54 (1).png>)

**残差平方和：**

RSS测量模型运行后回归函数和数据集之间的剩余误差量。**较小的残差平方和表示回归函数**

RSS（也称为残差平方和）本质上决定了回归模型解释或**表示模型中数据的能力**

残差平方和越**低**，**回归模型在解释数据方面就越好**

****

